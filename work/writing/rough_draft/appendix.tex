\section{Logit Regression}
	\label{app:logit}
In some parts of my analysis, I employ logit regression when analyzing a binary outcome--I will briefly explain that empirical method here. This is not a primary empirical method I employ to answer my question, but instead a model I use to analyze selection into kindergarten, attrition, and robustness checks for binary outcomes such as school completion or school attendance. 

The logit model differs from OLS in that it restricts the estimated probability from a function to between 0 and 1, improving our ability to interpret model estimates. It differs from the probit model in that it uses a logistic cumulative distribution function (c.d.f.), rather than a standard normal. Additionally, the logit model allows the use of fixed-effects, which I employ to analyze within-household selection. To be clear, when I present coefficients resulting from a logit model, those are the \textit{average} marginal effects (MEs)--calculated after model estimation. 

The logit model fits the following model:
\begin{gather}
	\text{Pr}(y_i = 1 | \mathbf{x}_i) = \Lambda(\mathbf{x}_i' \beta)
\end{gather}
where $\Lambda(.)$ is the logistic c.d.f., so that $\Lambda(z) = \frac{e^z}{1+e^z}$.

\section{Sample Attrition}
	\label{app:attrition}
As I discuss thoroughly in Section ~\ref{sec:data}, my sample suffers from attrition as I merge data from across different waves of the Indonesian Family Life Survey (IFLS). In this section, I examine that attrition and check whether it introduces bias into my estimates of kindergarten's effects.\footnote{In this section, when I discuss attrition, I am referring to total attrition, i.e., whether an individual was \textit{ever} lost to attrition--whether that be from merging across waves of the IFLS or from missing observations.}

Following the approach of Baulch and Quisumbing (2011), I used the set of covariates employed in the regression analysis as ell as variables collected on the quality of the initial childhood interview in 1997 \citep{Baulch2011}.\footnote{The two interview quality questions were the interviewer evaluation of the interviewed child's attention (on a scale of 1-5) and the interviewer evaluation of the respondent's answers' accuracy. The two are measures are highly correlated (their pair-wise correlation is 0.8941) and both have a significant, positive coefficient when predicting total attrition. I had to exclude some covariates because of a lack of variation in attrition; in particular, I excluded province fixed-effects, the two-parent household dummy, the birth order variable, and general health categorical variable. None of these variables were significant predictors of attrition in the first place. On another note, I employ logit regression rather than probit regression to ensure consistency with my analysis of switching and selection into kindergarten--on the other hand, Baulch and Quisimbing employ the latter.} There is variation in the resultant inverse probability weight; the mean weight is 1.07 and the median is 0.993. A basic t-test confirms that the mean weight is not 0, with a 95\% confidence interval of (1.06, 1.08).

I applied the inverse probability weight to both the OLS and IV models, focusing on years of education.\footnote{Since these inverse probability weights are calculated at the individual level, they vary within household and between siblings, thus disallowing me from using them in the mother fixed-effects model. If attrition is not significant at the individual level, then I would suspect it is not significant at the household level when switching attrition--which occurs at a significantly higher rate--is accounted for (which I do in Appendix ~\ref{app:switching}).} For the OLS model, my results are not different; the inclusion inverse probability weights slightly raises the point estimate of the effect of kindergarten from 0.66 to 0.65, and makes it slightly less precise with a standard error of 0.15, rather than the previous standard error of 0.14. The IV estimates, on the other hand, are more different; kindergarten's estimated effect on educational attainment is now 1.64, rather than 1.40--and the standard error is unchanged. Comparing the non-weighted model to the weighted models, there are no significant divergences in the coefficients of covariates. Because of my inability to apply inverse probability weights to the fixed-effects model and the absence of a significant difference for the OLS and IV estimates, I do not include inverse probability weights for the main results presented in this paper.

\section{Switching Sample Restriction}
	\label{app:switching}
As briefly discussed in Section ~\ref{sec:fe}, the employment of fixed-effects places additional stringent restrictions on my sample--resulting in loss of 93\% of my full sample when restricting to only the `switching' sample employed in the fixed-effects estimation.\footnote{To be transparent about this reduction in sample size, I have ensured that the sample size indicated at the foot of the regression tables with fixed-effects results \textit{only} includes the switching sample.}

I have also conducted basic analysis and diagnosis of the effects of this loss of sample. To begin, I have constructed a diagnosis scatterplot, Figure ~\ref{fig:scatter_switching}, to visualize selection into the switching sample. This graph allows us to make several observations. Province fixed-effects--which I employ for my OLS estimates--does not result in any attrition, since each group has a non-zero standard deviation in kindergarten attendance. On the other hand, there are many families, denoted by blue circles, with a standard deviation of zero in kindergarten attendance and that are thus removed from the sample. Nonetheless, these families still have a great deal of variance in educational attainment.

I also prepared a table capturing the summary statistics for all variables--the controls as well as outcome variables, since all observations in the table are not removed from the sample by the switching restrictoin, as seen in Table ~\ref{table:switching_stats}. There appears to be some selection bias into the switching sample--it appears that the switching sample is more educated than the non-switching sample, for example. I follow this with a logit model, employing my full set of covariates and province fixed-effects. The only significant predictors of switching status at a 95\% confidence level are kindergarten attendance (a positive effect), whether a household has two parents (a negative effect), a household expenditures in 1997 (a negative effect), and a household expenditures in 2000 (a positive effect).\footnote{ Some province dummies are positive significant, though none are significantly negative.} It makes sense kindergarten has significant positive margin effects; after all, some kindergarten attendance within a household is strictly necessary for switching status. Disregarding the expenditure variables (which appear to counteract one another) and kindergarten attendance, I conduct a joint significance test that the marginal effects for the most important variables for determining educational attainment are all equal to 0--and fail to reject the null hypothesis that none are significant.\footnote{ Specifically, I test the AMEs for household head's years of education, mother's years of education, urban (1997, 2000, and 2007), number of kindergartens per kecamatan (1990 and 2000), and kindergarten spillover from older siblings.} These results tentatively suggest that the loss of sample--despite its high rate--from the full sample to the switching sample does not bias my fixed-effects results.

On the other hand, the process of selection into kindergarten appears to be biased by this attrition. I run two separate logit regressions, one with only my switching sample and the other only with the non-switching sample. The switching sample logit reveals negative, significant AMEs for the kindergarten spillover variable and the total number of visits to a doctor--an inversion of both my theoretical expectations as well as the empirical findings from both the OLS and IV estimations of selection into kindergarten for the full sample. That comparison can be found in Table ~\ref{table:kinder_logit}. Additionally, the non-switching sample reflects strong positive effects for both the household head's years of education as well as the mother's--while the switching sample only shows significance for the latter, albeit with three times as large of a standard error. This is emblematic of the core problem with this sample loss--even if, as my analysis above suggests, there is not a clear bias in switching attrition, the sheer decrease in sample size results in imprecision and loss of efficiency in my estimates that cloud my results. This, in conjunction with the correlated error term issue I discuss later, motivate my use of instrumental variable (IV) estimation.

\section{Selection into Kindergarten Attendance}
	\label{app:kinder_sel}
To understand the role of kindergarten in human capital accumulation, it is necessary to first understand what drives kindergarten attendance. To understand this process, I used a series of logit regressions, the results of which can be found in Table ~\ref{table:kinder_logit}.\footnote{For information on the logit regression method, see Appendix ~\ref{app:logit}.} In this table I present the average marginal effects (AME) associated with each covariate. I included all of the covariates I used in my primary results, found in Section ~\ref{sec:results}. I organized the table into 3 model specifications: (1) full sample, full set of covariates, and no fixed-effects; (2) only the switching sample, full set of covariates, and no fixed-effects; and (3) only the switching sample, individual-level covariates, and fixed effects.\footnote{Recall that non-individual-level covariates would not be applicable to the fixed-effects model.}

We can make a few interesting observations. First, note the strength of one of my selected instruments--here included only as an ordinary regressor, the number of kindergartens per 10,000 people in each kecamatan in 1990. This confirms the strength of that instrument and motivates its use.\footnote{ When the 1990 variable is excluded, the number of kindergartens per 10,000 people in each kecamatan is similarly positive and statistically significant.} However, when restricted to the switching sample, this significance disappears. Additionally, household wealth and education, age, and whether an older sibling attended kindergarten are all positive and significant--although none are positive and significant for the switching sample. In fact, for the switching sample drastically the effect of an older sibling attending kindergarten is drastically changed to a strong negative one. This heterogeneity reflects the bias of small sample size inherent in my employment of fixed-effects and motivates the use of IV estimation. 

What is important to note is that the health indicators--insignificant in the OLS models here, as well as each of the OLS, fixed-effects, and IV models presented for educational outcomes--have significant and positive AMEs for the fixed-effects logit regression, when total visits to healthcare is also controlled for. Based on these results, it appears my covariates on the household and community level explain kindergarten attendance well, while my individual-level covariates--within a fixed-effects framework--provide an incomplete, yet suggestive, story of selection into kindergarten attendance.

\section{OLS Regression - Post-Estimation Analysis and Robustness Checks}
	\label{app:ols_post}
	\subsection{OLS Assumptions - Homoskedasticity and Zero Conditional Mean of Errors}
A natural starting point with analyzing the OLS results is to check 2 critical assumptions of OLS: 1) homoskedastic errors and 2) uncorrelated errors. Homoskedasticity requires that Var($u | x) = \sigma ^ 2$ for residual $u$ and explanatory variable $x$ (in all of my models, kindergarten attendance). Then uncorrelated errors require that errors are not correlated with values of the explanatory variable, or equivalently that the conditional mean of $u$ is 0: E$(u | x) = 0$. 

First, using the Breusch-Pagan/Cook-Weisberg test for heteroskedasticity, I reject the null hypothesis that errors exhibit constant variance, or equivalently are homoskedastic, for \textit{every} OLS model. This is not a problem, as heteroskedasticity does not bias our results so long as we ensure that reported standard errors are robust to heteroskedasticity. This does mean that the results of latent-variable models such as logit regression, are biased as they strictly require homoskedasticity. Thus, I do not use those regressions for my main results, and only for robustness checks.

Second, none of the OLS models exhibit any correlation between kindergarten attendance and their respective residuals--the residuals for each model exhibit a pair-wise correlation with kindergarten attendance of 0.0000. Thus, my results do not violate the zero conditional mean assumption of OLS and are not biased in this respect. 

	\subsection{Omitted Variables Bias and Specification Tests}
I suspect that my OLS models suffer from omitted variable bias because of unobservable mother characteristics influencing educational attainment. One way to check this is through specification tests, such as Ramsey's RESET test, in which powers of fitted values of the outcome variable are added to the regression \citep{Long1992,Ramsey1969}. Then a joint significance test is conducted to check whether, jointly, these coefficients are equal to 0; if so, then the initial model specification is adequate, and if not then the initial model specification is inadequate and there may be non-linearity or an omitted variable. The Ramsey test leads me to reject the null hypothesis that there are no omitted variables for each model; this finding is what motivates my use of mother fixed-effects, as I theorize unobserved mother characteristics--omitted in the OLS models--have a critical impact on educational outcomes. 

There are other ways to examine the adequacy of a model, along the same conceptual lines as the Ramsey test, i.e., fitting a richer model and testing whether the new variables are jointly significant. To further test omitted variable bias, then, I create an exhaustive set of interaction terms, with kindergarten interacted with every one of the covariates in the fully-specified OLS model, and include these as variables alongside the original covariates. I then conduct a basic Wald Test on the null hypothesis that the joint significance of these terms is 0. For every model I reject the null hypothesis, further suggesting that my OLS estimates suffer from omitted variable bias and that the omitted variables are not only interaction or non-linear terms with existing variables.

Finally, I need to check whether kindergarten attendance, my independent variable, is endogenous. At 95\% confidence, I reject the null hypothesis that kindergarten attendance is exogenous for all models except those with the following outcome variables: senior completion; school attendance in the 2nd, 3rd, 4th, 5th, 10th, 11th, 12th, 13th, and 14th grades; stay-on after the 6th, 9th, and 12th grade; and cognitive performance in 2000, 2007, and 2014. This does not invalidate my IV approach, as my instruments largely satisfy the two assumptions of IV estimation, but it does strengthen the OLS estimates.

	\subsection{Switching Sample}
		\label{app:switching_ols}
Because of worries about bias resulting from nonrandom selection into the switching sample that the mother fixed-effects model uses, I can run the OLS estimation for only the switching to check if selection into switching induces heterogeneity in the effects of kindergarten.\footnote{See Appendix ~\ref{app:switching} for more detail and analysis of selection into the switching sample.} As I would predict given the drastic reduction in size from the non-switching sample to the switching sample (the latter is 7\% the size of the former), the standard errors are significantly higher for the OLS models restricted to the the switching sample: none of the coefficients for kindergarten attendance are statistically significant, either positively or negatively, for any of the outcome variables. Thus, even if there is not clear bias in selection into the switching sample, the sheer magnitude of the attrition is introducing bias into the fixed-effects estimations.

	\subsection{Migration}
	\label{app:mig}
Intra-Indonesia migration between IFLS waves may introduce confounding factors into my analysis, although I do not anticipate it being a significant issue because 1) improved educational opportunities resulting from moving would be absorbed by the schools per 10,000 variable and 2) improved economic opportunities resulting from moving would be absorbed by the household per capita expenditure variable. Both these variables are collected over time, so they are not fixed in one place. Nonetheless, it is worthwhile to investigate whether kindergarten effects substantively differ between the total sample and migrating sub-samples. 

For this section, I define migration simply as whether an individual completed the IFLS identifying with a different combination of province, kabupaten, and kecamatan from one wave to another. Further, I break migration into two types: 1) migration that would have occurred while a child was in school, between 1997 and 2007, and 2) migration that occurred between 2007 and 2014, around when a child would be coming-of-age and exiting school. Overall, 61.8\% of the sample migrated between 1997 and 2007, and 8.99\% of the sample migrated between 2007 and 2014.

The results for the migrating sub-samples are mixed. First, for the sub-sample that migrated between 1997 and 2007, the effect of kindergarten on years of education and junior high school completion is approximately halved, but remains significant positive. Overall, for this sub-sample the estimates of kindergarten's effects tend to be similar as for the main sample, albeit with lower magnitude and insignificance in some cases. Second, for the sub-sample that migrated between 2007 and 2014, the results are similar but mostly of a greater magnitude. The most notable difference is that, unlike for the 1997-2007 migrating sub-sample and the total sample, for the 2007-2014 migrating sub-sample, kindergarten had a significant positive effect on the completion of junior high and senior high, and kindergarten effects actually increased over time, the opposite of fadeout. This motivates further research into the role of migration in educational attainment.

\section{IV Estimation - Post-Estimation Analysis and Robustness Checks}
	\label{app:iv_robust}
	\subsection{Treatment Effects IV Model}
There are several robustness checks I can conduct for the IV Estimations. First, I can add structure to the IV estimations involving a binary independent variable by employing a latent-variable model in the first-stage regression--creating one type of `treatment-effects' instrument variable model. Since kindergarten attendance, a binary variable, is the treatment variable for all of my models, I can employ this robustness check to every specified model in the paper. I compare the results of the treatment-effects model to the basic model. Critically, all of the IV estimates exhibit some degree of heteroskedasticity; this does not bias the IV results since I can employ a weighting matrix optimal for heteroskedastic errors. However, for the latent-variable model used in this treatment-effects model, heteroskedastic errors \textit{do} bias estimates. Thus, while these results are suggestive as a robustness check, they are biased and should be viewed with skepticism.

Comparing the two types of IV models, there are significant differences: most prominently, the treatment-effects models estimates kindergarten has a strong significant negative effect on elementary completion and a significant negative effect on school attendance in the 3rd, 4th, 5th, 6th. Note that kindergarten's effect on none of these outcomes was found to be significant using GMM IV estimation. Other than these outcome variables, the results either matched or were slightly less significant than the results from the GMM IV estimation.

	\subsection{Switching Sample}
Much like I did above, in Appendix ~\ref{app:switching_ols}, I can run the IV estimation for only the switching sub-sample. The results of this robustness check are largely the same as for the OLS estimates; the standard errors are rendered so large for the coefficient of kindergarten attendance as to make all estimates insignificant, either positively or negatively.

	\subsection{Alternative Instruments}
In this section, I examine the implications of selecting alternative instruments, in particular: 1) focusing exclusively on private kindergartens, 2) focusing exclusively on public kindergartens, and 3) the percent change of the number of kindergartens per 10,000 people in each kecamatan. Unsurprisingly, the IV estimates using only private kindergartens in 1990 and 2000 as instruments were nearly identical to the estimates using the total number of kindergartens--as nearly all kindergartens were private.\footnote{There is a 0.9865 correlation between the private and total in 1990 and a 0.9876 correlation in 2000.} On the other hand, the IV estimates using only the public kindergartens in 1990 and 2000 as instruments were imprecise and no kindergarten effect for any outcome was statistically significant.\footnote{Given the sheer paucity of public kindergartens, there is a 0.0997 correlation between public and total in 1990 and a 0.3069 correlation in 2000.} The percentage change in kindergarten is a perplexing instrument; in the first-stage regression, it has a significant (with a t-value of -5.21) negative coefficient of -0.0001783. Nevertheless, none of its estimates of kindergarten's effects are statistically significant. I hypothesize this is because increases in kindergartens were heavily concentrated in places with little to no kindergarten to begin with, in 1990. 

	\subsection{Migration}
See Appendix ~\ref{app:mig} for a description of how I treat migration. First, kindergarten's effects are now entirely insignificant for the sub-sample that migrated between 1997 and 2014. Second, the effect of kindergarten is insignificant for every outcome for those that migrated between 2007 and 2014, I hypothesize because of the loss of 91.01\% of the total sample when restricting to the 2007-2014 migrating sub-sample. Much like the parallel OLS robustness check, this finding warrants further analysis of the role that migration plays in educational attainment and the effects of kindergarten.




